# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sMfAmtcTIoTrFw64YTzFDtCj8CVuYzwP
"""

!pip install python-terrier

import pyterrier as pt
if not pt.started():
   pt.init()

!pip install Arabic-stopwords

import pandas as pd
pd.set_option('display.max_colwidth', 150)
import re
 
from snowballstemmer import stemmer

import arabicstopwords.arabicstopwords as stp

    #make your loops show a smart progress meter 

from tqdm import tqdm

docs_df = pd.DataFrame([ 

                        ["d0", "هذا هو المعمل الثاني من دورة استرجاع المعلومات"],

                        ["d1", " سنتعلم في هذا اللاب كيفية التعامل مع النصوص العربية "], 

                        ["d2", "اليوم هو 29 سبتمبر 2022 المرافق يوم الخميس 23 من ربيع الاول 1444 "], 

                        ["d3", "في هذا المعمل ستتعرف على طرق تحضير البيانات و تشذيب النصوص العربية"]

                      ],

                        columns=["docID", "raw_text"])


docs_df

stp.stopwords_list()

len(stp.stopwords_list())

#removing Stop Words function

def remove_stopWords(sentence):

    terms=[]

    stopWords= set(stp.stopwords_list())

    for term in sentence.split() : 

        if term not in stopWords :

           terms.append(term)

    return " ".join(terms)


docs_df["Removed_Stop_word_text"]=docs_df["raw_text"].apply(remove_stopWords)

print("***************************************************************************documents after removing stopwords*********************************************************************")

docs_df

#a function to normalize the tweets

def normalize(text):

    text = re.sub("[إأٱآا]", "ا", text)

    text = re.sub("ى", "ي", text)

    text = re.sub("ؤ", "ء", text)

    text = re.sub("ئ", "ء", text)

    text = re.sub("ة", "ه", text)

    return(text)


docs_df["normalized_text"]=docs_df["Removed_Stop_word_text"].apply(normalize)

print("***************************************************************************documents after normalizing*********************************************************************")

docs_df

#specify that we want to stem arabic text

ar_stemmer = stemmer("arabic")

#define the stemming function

def stem(sentence):

    return " ".join([ar_stemmer.stemWord(i) for i in sentence.split()])


docs_df['Stemtext']=docs_df['normalized_text'].apply(stem)

print("***************************************************************************documents after stemming*********************************************************************")

docs_df

fiilee= open("C:\Users\hp\Downloads\01bool.pdf","r")